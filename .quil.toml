[core]
# default command to run
default_command = "generate"
# default provider to use
default_provider = "gemini"
# cache ttl
cache_ttl = "24h"
# retry attempts
retry_attempts = 3
# how many variations to generate (0 for auto-select; max 5)
candidate_count = 3

[providers]
  [providers.anthropic]
    model = "claude-3-5-sonnet-20241022"
    max_tokens = 4096
    temperature = 0.3

    
  [providers.openai]
    model = "gpt-4o"
    max_tokens = 4096
    temperature = 0.3


  [providers.gemini]
    model = "gemini-1.5-flash"
    max_tokens = 4096
    temperature = 0.3

  [providers.ollama]
    model = "qwen2.5-8b-instruct"
    max_tokens = 4096
    temperature = 0.3
